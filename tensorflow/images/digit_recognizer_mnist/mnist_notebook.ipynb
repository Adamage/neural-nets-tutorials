{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tools import Tools, SimpleMnistTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section defines hyperparameters. In simple terms, these are the numbers on which the training depends very much, and its hard to predict just how much. Especially: learning rate, which defines how 'far' should gradients be used to shift vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "TRAINING_ITERATIONS = 1500\n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 50\n",
    "VALIDATION_SIZE = 2000\n",
    "IMAGE_TO_DISPLAY = 10\n",
    "LOCAL_PATH = 'data'\n",
    "TRAIN_DATA = os.path.join(LOCAL_PATH, \"train.csv\")\n",
    "TEST_DATA = os.path.join(LOCAL_PATH, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data(42000,785)\n   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0       0    ...            0         0         0         0         0   \n1       0    ...            0         0         0         0         0   \n2       0    ...            0         0         0         0         0   \n3       0    ...            0         0         0         0         0   \n4       0    ...            0         0         0         0         0   \n\n   pixel779  pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0         0  \n1         0         0         0         0         0  \n2         0         0         0         0         0  \n3         0         0         0         0         0  \n4         0         0         0         0         0  \n\n[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(TRAIN_DATA)\n",
    "print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data.iloc[:, 1:].values\n",
    "images = images.astype(np.float)\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "image_size = images.shape[1]\n",
    "Tools.display(images[33], 28, 28)\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_flat = data[[0]].values.ravel()\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "labels = Tools.dense_to_hot(labels_flat, labels_count)\n",
    "labels = labels.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin defining all variables involved in computational graph. The SimpleMnistTrainer is a small class in tools.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', shape=[None, image_size])\n",
    "y_labels = tf.placeholder('float', shape=[None, labels_count])\n",
    "trainer = SimpleMnistTrainer()\n",
    "trainer.train_images = train_images\n",
    "trainer.train_labels = train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define weights and biases in first layer. Define RELU (rectifined linear) 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = Tools.weight_variable(shape=[5, 5, 1, 32])\n",
    "b_conv1 = Tools.bias_variable([32])\n",
    "image = tf.reshape(x, [-1, image_width, image_height, 1])\n",
    "h_conv1 = tf.nn.relu(Tools.convolution2d(image, W_conv1) + b_conv1)\n",
    "h_pool1 = Tools.max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape to make a layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 32 features in 4 by 8 grid\n",
    "layer1 = tf.reshape(h_conv1, (-1, image_height, image_width, 4, 8))\n",
    "\n",
    "# reorder: channels, x, y\n",
    "layer1 = tf.transpose(layer1, (0, 3, 1, 4, 2))\n",
    "layer1 = tf.reshape(tensor=layer1, shape=(int(image_height) * 4, int(image_width * 8)), name=\"Layer1Reshape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define weights and biases in second layer. Define RELU (rectifined linear) 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = Tools.weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = Tools.bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(Tools.convolution2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = Tools.max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 64 features in 4 by 16 grid\n",
    "layer2 = tf.reshape(h_conv2, (-1, 14, 14, 4, 16))\n",
    "\n",
    "# reorder so the channels are in the first dimension, x and y follow.\n",
    "layer2 = tf.transpose(layer2, (0, 3, 1, 4, 2))\n",
    "layer2 = tf.reshape(layer2, (-1, 14 * 4, 14 * 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define third layer - densely connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = Tools.weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = Tools.bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional algorithms. To prevent overfitting, use drop-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder('float')\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final layer is the output layer, a 'softmax', to convert output to one of 10 classes, for 10 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = Tools.weight_variable([1024, labels_count])\n",
    "b_fc2 = Tools.bias_variable([labels_count])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having all the layers defined, now we specify how we are going to train the network. Define cost function, optimisation for gradient descent, and how to evaluate accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "cross_entropy = -tf.reduce_sum(y_labels * tf.log(y))\n",
    "# optimisation function\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(cross_entropy)\n",
    "# evaluate\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "predict = tf.argmax(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize variables for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 40000\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "validation_accuracies = []\n",
    "x_range = []\n",
    "display_step = 10\n",
    "epochs_completed = 0\n",
    "index_in_epoch = 0\n",
    "num_examples = train_images.shape[0]\n",
    "trainer.number_of_examples = num_examples\n",
    "print(\"Number of examples: \" + str(num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save our model periodically, use Tensorflow checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables())\n",
    "MODEL_PATH = os.path.join(LOCAL_PATH, \"model.ckpt\")\n",
    "tf.summary.scalar(\"cost\", cross_entropy)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summary_operations = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we start a Tensorflow session. During this session, all variables are initiated and computational graph is created. To be abble to start training from a previously saved checkpoint, implement a simple check if a checkpoint already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.05999999865889549 | validation_accuracy : 0.11999999731779099 |  for step 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.3400000035762787 | validation_accuracy : 0.2199999988079071 |  for step 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.4000000059604645 | validation_accuracy : 0.41999998688697815 |  for step 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.5 | validation_accuracy : 0.6600000262260437 |  for step 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.7400000095367432 | validation_accuracy : 0.6800000071525574 |  for step 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.5799999833106995 | validation_accuracy : 0.7400000095367432 |  for step 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.800000011920929 | validation_accuracy : 0.800000011920929 |  for step 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.7400000095367432 | validation_accuracy : 0.8399999737739563 |  for step 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.8399999737739563 | validation_accuracy : 0.8199999928474426 |  for step 80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.800000011920929 | validation_accuracy : 0.8999999761581421 |  for step 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.8999999761581421 | validation_accuracy : 0.8799999952316284 |  for step 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.8799999952316284 | validation_accuracy : 0.9399999976158142 |  for step 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.8999999761581421 | validation_accuracy : 0.9399999976158142 |  for step 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 1.0 | validation_accuracy : 0.9599999785423279 |  for step 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.9200000166893005 | validation_accuracy : 0.9599999785423279 |  for step 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.9399999976158142 | validation_accuracy : 0.9599999785423279 |  for step 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.9599999785423279 | validation_accuracy : 0.9399999976158142 |  for step 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.9800000190734863 | validation_accuracy : 0.9599999785423279 |  for step 800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy: 0.9800000190734863 | validation_accuracy : 0.9599999785423279 |  for step 900\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to rename: data\\model.ckpt.index.tempstate11203692852574486313 to: data\\model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable/Adam_2, Variable/Adam_3, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_1/Adam_2, Variable_1/Adam_3, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_2/Adam_2, Variable_2/Adam_3, Variable_3, Variable_3/Adam, Variable_3/Adam_1, Variable_3/Adam_2, Variable_3/Adam_3, Variable_4, Variable_4/Adam, Variable_4/Adam_1, Variable_4/Adam_2, Variable_4/Adam_3, Variable_5, Variable_5/Adam, Variable_5/Adam_1, Variable_5/Adam_2, Variable_5/Adam_3, Variable_6, Variable_6/Adam, Variable_6/Adam_1, Variable_6/Adam_2, Variable_6/Adam_3, Variable_7, Variable_7/Adam, Variable_7/Adam_1, Variable_7/Adam_2, Variable_7/Adam_3, beta1_power, beta1_power_1, beta2_power, beta2_power_1)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Program Files\\Python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-84f249627a2a>\", line 1, in <module>\n    saver = tf.train.Saver(tf.global_variables())\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 689, in build\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 276, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 219, in save_op\n    tensors)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 780, in save_v2\n    tensors=tensors, name=name)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nUnknownError (see above for traceback): Failed to rename: data\\model.ckpt.index.tempstate11203692852574486313 to: data\\model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable/Adam_2, Variable/Adam_3, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_1/Adam_2, Variable_1/Adam_3, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_2/Adam_2, Variable_2/Adam_3, Variable_3, Variable_3/Adam, Variable_3/Adam_1, Variable_3/Adam_2, Variable_3/Adam_3, Variable_4, Variable_4/Adam, Variable_4/Adam_1, Variable_4/Adam_2, Variable_4/Adam_3, Variable_5, Variable_5/Adam, Variable_5/Adam_1, Variable_5/Adam_2, Variable_5/Adam_3, Variable_6, Variable_6/Adam, Variable_6/Adam_1, Variable_6/Adam_2, Variable_6/Adam_3, Variable_7, Variable_7/Adam, Variable_7/Adam_1, Variable_7/Adam_2, Variable_7/Adam_3, beta1_power, beta1_power_1, beta2_power, beta2_power_1)]]\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: data\\model.ckpt.index.tempstate11203692852574486313 to: data\\model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable/Adam_2, Variable/Adam_3, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_1/Adam_2, Variable_1/Adam_3, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_2/Adam_2, Variable_2/Adam_3, Variable_3, Variable_3/Adam, Variable_3/Adam_1, Variable_3/Adam_2, Variable_3/Adam_3, Variable_4, Variable_4/Adam, Variable_4/Adam_1, Variable_4/Adam_2, Variable_4/Adam_3, Variable_5, Variable_5/Adam, Variable_5/Adam_1, Variable_5/Adam_2, Variable_5/Adam_3, Variable_6, Variable_6/Adam, Variable_6/Adam_1, Variable_6/Adam_2, Variable_6/Adam_3, Variable_7, Variable_7/Adam, Variable_7/Adam_1, Variable_7/Adam_2, Variable_7/Adam_3, beta1_power, beta1_power_1, beta2_power, beta2_power_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5d1da9521943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Train loop finished. Check final accuracy on validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[0;32m   1389\u001b[0m       model_checkpoint_path = sess.run(\n\u001b[0;32m   1390\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1391\u001b[1;33m           {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1392\u001b[0m       \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: data\\model.ckpt.index.tempstate11203692852574486313 to: data\\model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable/Adam_2, Variable/Adam_3, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_1/Adam_2, Variable_1/Adam_3, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_2/Adam_2, Variable_2/Adam_3, Variable_3, Variable_3/Adam, Variable_3/Adam_1, Variable_3/Adam_2, Variable_3/Adam_3, Variable_4, Variable_4/Adam, Variable_4/Adam_1, Variable_4/Adam_2, Variable_4/Adam_3, Variable_5, Variable_5/Adam, Variable_5/Adam_1, Variable_5/Adam_2, Variable_5/Adam_3, Variable_6, Variable_6/Adam, Variable_6/Adam_1, Variable_6/Adam_2, Variable_6/Adam_3, Variable_7, Variable_7/Adam, Variable_7/Adam_1, Variable_7/Adam_2, Variable_7/Adam_3, beta1_power, beta1_power_1, beta2_power, beta2_power_1)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Program Files\\Python35\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Program Files\\Python35\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-20-84f249627a2a>\", line 1, in <module>\n    saver = tf.train.Saver(tf.global_variables())\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1056, in __init__\n    self.build()\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 689, in build\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 276, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 219, in save_op\n    tensors)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 780, in save_v2\n    tensors=tensors, name=name)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Program Files\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nUnknownError (see above for traceback): Failed to rename: data\\model.ckpt.index.tempstate11203692852574486313 to: data\\model.ckpt.index : Access is denied.\r\n; Input/output error\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable/Adam, Variable/Adam_1, Variable/Adam_2, Variable/Adam_3, Variable_1, Variable_1/Adam, Variable_1/Adam_1, Variable_1/Adam_2, Variable_1/Adam_3, Variable_2, Variable_2/Adam, Variable_2/Adam_1, Variable_2/Adam_2, Variable_2/Adam_3, Variable_3, Variable_3/Adam, Variable_3/Adam_1, Variable_3/Adam_2, Variable_3/Adam_3, Variable_4, Variable_4/Adam, Variable_4/Adam_1, Variable_4/Adam_2, Variable_4/Adam_3, Variable_5, Variable_5/Adam, Variable_5/Adam_1, Variable_5/Adam_2, Variable_5/Adam_3, Variable_6, Variable_6/Adam, Variable_6/Adam_1, Variable_6/Adam_2, Variable_6/Adam_3, Variable_7, Variable_7/Adam, Variable_7/Adam_1, Variable_7/Adam_2, Variable_7/Adam_3, beta1_power, beta1_power_1, beta2_power, beta2_power_1)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    log_writer = tf.summary.FileWriter(LOCAL_PATH, graph=tf.get_default_graph())\n",
    "    \n",
    "    # This part handles resuming from a checkpoint.\n",
    "    if os.path.isfile(MODEL_PATH + \".meta\"):\n",
    "        ckpt = tf.train.get_checkpoint_state(LOCAL_PATH)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(session, ckpt.model_checkpoint_path)\n",
    "    \n",
    "    # Do if no checkpoints are found.\n",
    "    else:\n",
    "        for i in range(TRAINING_ITERATIONS):\n",
    "            \n",
    "            batch_xs, batch_ys = trainer.next_batch(BATCH_SIZE)\n",
    "            \n",
    "            if i % display_step == 0 or (i + 1) == TRAINING_ITERATIONS:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x: batch_xs, y_labels: batch_ys, keep_prob: 1.0})\n",
    "\n",
    "                validation_accuracy = accuracy.eval(feed_dict={x: validation_images[0:BATCH_SIZE],\n",
    "                                                               y_labels: validation_labels[0:BATCH_SIZE],\n",
    "                                                               keep_prob: 1.0})\n",
    "                \n",
    "                print('training_accuracy: {0} | validation_accuracy : {1} |  for step {2}'\n",
    "                      .format(train_accuracy, validation_accuracy, i))\n",
    "                \n",
    "                validation_accuracies.append(validation_accuracy)\n",
    "                train_accuracies.append(train_accuracy)\n",
    "                x_range.append(i)\n",
    "                \n",
    "                # Increase display_step.\n",
    "                if i % (display_step * 10) == 0 and i:\n",
    "                    display_step *= 10\n",
    "\n",
    "            summary, acc = session.run([summary_operations, train_step], feed_dict={x: batch_xs, y_labels: batch_ys, keep_prob: DROPOUT})\n",
    "            log_writer.add_summary(summary, global_step=i)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                saver.save(session, MODEL_PATH)\n",
    "\n",
    "        # Train loop finished. Check final accuracy on validation set\n",
    "        validation_accuracy = accuracy.eval(feed_dict={x: validation_images,\n",
    "                                                       y_labels: validation_labels,\n",
    "                                                       keep_prob: 1.0})\n",
    "        print('validation_accuracy => %.4f' % validation_accuracy)\n",
    "        plt.plot(x_range, train_accuracies, '-b', label='Training')\n",
    "        plt.plot(x_range, validation_accuracies, '-g', label='Validation')\n",
    "        plt.legend(loc='lower right', frameon=False)\n",
    "        plt.ylim(ymax=1.1, ymin=0.7)\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('step')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = pd.read_csv(TEST_DATA).values\n",
    "test_images = test_images.astype(np.float)\n",
    "test_images = np.multiply(test_images, 1.0 / 255.0)\n",
    "\n",
    "predicted_labels = np.zeros(test_images.shape[0])\n",
    "for i in range(0, test_images.shape[0] // BATCH_SIZE):\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write(\".\")\n",
    "    predicted_labels[i * BATCH_SIZE: (i + 1) * BATCH_SIZE] = \\\n",
    "        predict.eval(feed_dict={x: test_images[i * BATCH_SIZE: (i + 1) * BATCH_SIZE], keep_prob: 1.0})\n",
    "\n",
    "print('predicted_labels({0})'.format(len(predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show test image and prediction\n",
    "Tools.display(test_images[IMAGE_TO_DISPLAY], image_width, image_height)\n",
    "print('predicted_labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY, predicted_labels[IMAGE_TO_DISPLAY]))\n",
    "\n",
    "test_images = StandardScaler().fit_transform(np.float32(test_images.values))\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "layer1_grid = layer1.eval(feed_dict={x: test_images[IMAGE_TO_DISPLAY:IMAGE_TO_DISPLAY + 1], keep_prob: 1.0})\n",
    "plt.imshow(test_images[k, :, :, 0])\n",
    "plt.show()\n",
    "print(predicted_labels[IMAGE_TO_DISPLAY])\n",
    "\n",
    "layer2_grid = layer2.eval(feed_dict={x: test_images[IMAGE_TO_DISPLAY:IMAGE_TO_DISPLAY + 1], keep_prob: 1.0})\n",
    "plt.imshow(layer2_grid[0])"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}